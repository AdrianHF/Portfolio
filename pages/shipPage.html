<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Kaggle Titanic</title>
  <link rel="icon" type="image/svg+xml" href="../assets/svgIcons/ship.svg">
  <link rel="stylesheet" href="../css/shipPage.css">
  <link rel='stylesheet' href="../css/prism.css">


  <style>
    @import url('https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Oswald:wght@200..700&display=swap');
    @import url('https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Oswald:wght@200..700&family=Roboto:ital,wght@0,100..900;1,100..900&display=swap');
  </style>

</head>

<body>




  <div id="headerDiv">
    <button id="goBackButton" onclick="window.location.href='../index.html'">


      <svg width='100%' height='100%' version="1.1" id="treeIconBox" xmlns="http://www.w3.org/2000/svg"
        xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 50" xml:space="preserve">
        <rect height="100%" width="100%" rx="6" ry="6" stroke="black" stroke-width="1" fill="White" />
        <line id="line1" x1="50%" y1="100%" x2="50%" y2="88%" stroke="black" stroke-width="0.2" />
        <line id="line2" x1="50%" y1="88%" x2="40%" y2="78%" stroke="black" stroke-width="0.2" />
        <line id="line3" x1="40%" y1="78%" x2="33%" y2="74%" stroke="black" stroke-width="0.2" />
        <line id="line4" x1="33%" y1="74%" x2="30%" y2="61%" stroke="black" stroke-width="0.2" />
        <line id="line5" x1="30%" y1="61%" x2="19%" y2="52%" stroke="black" stroke-width="0.2" />
        <line id="line6" x1="40%" y1="77%" x2="38%" y2="66%" stroke="black" stroke-width="0.2" />
        <line id="line7" x1="38%" y1="66%" x2="36%" y2="55%" stroke="black" stroke-width="0.2" />
        <line id="line8" x1="38%" y1="66%" x2="39%" y2="59%" stroke="black" stroke-width="0.2" />
        <line id="line9" x1="50%" y1="88%" x2="45%" y2="77%" stroke="black" stroke-width="0.2" />
        <line id="line10" x1="45%" y1="77%" x2="44%" y2="56%" stroke="black" stroke-width="0.2" />
        <line id="line11" x1="44%" y1="56%" x2="40%" y2="44%" stroke="black" stroke-width="0.2" />
        <line id="line12" x1="40%" y1="44%" x2="41.5%" y2="29%" stroke="black" stroke-width="0.2" />
        <line id="line13" x1="41.5%" y1="29%" x2="33%" y2="25%" stroke="black" stroke-width="0.2" />
        <line id="line14" x1="41.5%" y1="29%" x2="41%" y2="20%" stroke="black" stroke-width="0.2" />
        <line id="line15" x1="45%" y1="77%" x2="51.5%" y2="62%" stroke="black" stroke-width="0.2" />
        <line id="line16" x1="51.5%" y1="62%" x2="46%" y2="44%" stroke="black" stroke-width="0.2" />
        <line id="line17" x1="51.5%" y1="62%" x2="53%" y2="53%" stroke="black" stroke-width="0.2" />
        <line id="line18" x1="50%" y1="88%" x2="55%" y2="79%" stroke="black" stroke-width="0.2" />
        <line id="line19" x1="55%" y1="79%" x2="54.5%" y2="71%" stroke="black" stroke-width="0.2" />
        <line id="line20" x1="54.5%" y1="71%" x2="57%" y2="58%" stroke="black" stroke-width="0.2" />
        <line id="line21" x1="57%" y1="58%" x2="55%" y2="45%" stroke="black" stroke-width="0.2" />
        <line id="line22" x1="55%" y1="45%" x2="57%" y2="36%" stroke="black" stroke-width="0.2" />
        <line id="line23" x1="57%" y1="36%" x2="56%" y2="24%" stroke="black" stroke-width="0.2" />
        <line id="line24" x1="56%" y1="24%" x2="51%" y2="11%" stroke="black" stroke-width="0.2" />
        <line id="line25" x1="57%" y1="58%" x2="61%" y2="50%" stroke="black" stroke-width="0.2" />
        <line id="line26" x1="61%" y1="50%" x2="67%" y2="47%" stroke="black" stroke-width="0.2" />
        <line id="line27" x1="67%" y1="47%" x2="62.5%" y2="37.5%" stroke="black" stroke-width="0.2" />
        <line id="line28" x1="67%" y1="47%" x2="74%" y2="37%" stroke="black" stroke-width="0.2" />
        <line id="line29" x1="55%" y1="79%" x2="63%" y2="75%" stroke="black" stroke-width="0.2" />
        <line id="line30" x1="63%" y1="75%" x2="70%" y2="74%" stroke="black" stroke-width="0.2" />
        <line id="line31" x1="70%" y1="74%" x2="75%" y2="66%" stroke="black" stroke-width="0.2" />
        <line id="line32" x1="70%" y1="74%" x2="74%" y2="72%" stroke="black" stroke-width="0.2" />

        <circle id="circle1" cx="50%" cy="88%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle2" cx="40%" cy="78.3%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle3" cx="33%" cy="74%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle4" cx="30%" cy="61%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle5" cx="19%" cy="52%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle6" cx="38%" cy="66%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle7" cx="36%" cy="55%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle8" cx="39%" cy="59%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle9" cx="45%" cy="77%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle10" cx="44%" cy="56%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle11" cx="40%" cy="44%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle12" cx="41.5%" cy="29%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle13" cx="33%" cy="25%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle14" cx="41%" cy="20%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle15" cx="51.5%" cy="62%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle16" cx="46%" cy="44%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle17" cx="53%" cy="53%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle18" cx="55%" cy="79%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle19" cx="54.5%" cy="71%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle20" cx="57%" cy="58%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle21" cx="55%" cy="45%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle22" cx="57%" cy="36%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle23" cx="56%" cy="24%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle24" cx="51%" cy="11%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle25" cx="61%" cy="50%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle26" cx="67%" cy="47%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle27" cx="62.5%" cy="37.58%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle28" cx="74%" cy="37%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle29" cx="63%" cy="75%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle30" cx="70%" cy="74%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle31" cx="75%" cy="66%" stroke="black" stroke-width="0.2" fill="White" r="2%" />
        <circle id="circle32" cx="74%" cy="72%" stroke="black" stroke-width="0.2" fill="White" r="2%" />

      </svg>

      <p id="goBackText"> GO <br> BACK</p>
    </button>

    <h1 id="title">Titanic - Machine Learning from Disaster</h1>
  </div>

  <div id="container">

    <div id="textDiv">
      <p>


        The Titanic: Machine Learning from Disaster project on Kaggle
        is a popular data science competition.

        The objective is to develop a predictive model that determines whether
        a given passenger survived the Titanic disaster. This is achieved by analyzing
        a dataset that includes variables such as the passenger’s age, sex, fare, cabin,
        embarkation point, among others.

        <br>





      </p>


    </div>
    <div id='expandButtonDiv'>

      <img id='expandButton' src="../assets/svgIcons/expand.svg" alt="Expand Icon" width="30px" height="30px">

    </div>

    <div id="textDiv1">


      <g id="transparentText">
        <p class="column">
          <br>
          Since this is my first project using Artificial Intelligence,
          I wanted to see how far I could go without the need for a specific
          tutorial or any external help. Throughout the process, I learned about
          statistics and various AI models that could assist me with this task.
          Here is how it went:
          <br></br>
          This competition presents two datasets containing passenger information from the historic RMS Titanic:
          <br></br>
        </p>
        <div id="twoColumns">

          <div class="column">
            <p>

              <span class="rounded-highlight"> train.csv:</span> Contains details for 891 passengers with survival
              outcomes:
            <table>
              <thead>
                <tr>
                  <th>PassengerId</th>
                  <th>Survived</th>
                  <th>Pclass</th>
                  <th>Name</th>
                  <th>Sex</th>
                  <th>Age</th>
                  <th>SibSp</th>
                  <th>Parch</th>
                  <th>Ticket</th>
                  <th>Fare</th>
                  <th>Cabin</th>
                  <th>Embarked</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>1</td>
                  <td>0</td>
                  <td>3</td>
                  <td>Braund, Mr. Owen Harris</td>
                  <td>male</td>
                  <td>22.0</td>
                  <td>1</td>
                  <td>0</td>
                  <td>A/5 21171</td>
                  <td>7.2500</td>
                  <td>NaN</td>
                  <td>S</td>
                </tr>
                <tr>
                  <td>2</td>
                  <td>1</td>
                  <td>1</td>
                  <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>
                  <td>female</td>
                  <td>38.0</td>
                  <td>1</td>
                  <td>0</td>
                  <td>PC 17599</td>
                  <td>71.2833</td>
                  <td>C85</td>
                  <td>C</td>
                </tr>
                <tr>
                  <td>3</td>
                  <td>1</td>
                  <td>3</td>
                  <td>Heikkinen, Miss. Laina</td>
                  <td>female</td>
                  <td>26.0</td>
                  <td>0</td>
                  <td>0</td>
                  <td>STON/O2. 3101282</td>
                  <td>7.9250</td>
                  <td>NaN</td>
                  <td>S</td>
                </tr>
                <tr>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                </tr>
                <tr>
                  <td>889</td>
                  <td>1</td>
                  <td>1</td>
                  <td>Behr, Mr. Karl Howell</td>
                  <td>male</td>
                  <td>26.0</td>
                  <td>0</td>
                  <td>0</td>
                  <td>111369</td>
                  <td>30.0000</td>
                  <td>C148</td>
                  <td>C</td>
                </tr>
                <tr>
                  <td>890</td>
                  <td>1</td>
                  <td>1</td>
                  <td>Behr, Mr. Karl Howell</td>
                  <td>male</td>
                  <td>26.0</td>
                  <td>0</td>
                  <td>0</td>
                  <td>111369</td>
                  <td>30.0000</td>
                  <td>C148</td>
                  <td>C</td>
                </tr>
                <tr>
                  <td>891</td>
                  <td>0</td>
                  <td>3</td>
                  <td>Dooley, Mr. Patrick</td>
                  <td>male</td>
                  <td>32.0</td>
                  <td>0</td>
                  <td>0</td>
                  <td>370376</td>
                  <td>7.7500</td>
                  <td>NaN</td>
                  <td>Q</td>
                </tr>
              </tbody>
            </table>
            </p>
          </div>

          <div class="column">

            <p>
              <span class="rounded-highlight">test.csv:</span> Contains 418 additional passengers data without
              survival outcomes:
            <table>
              <thead>
                <tr>
                  <th>PassengerId</th>
                  <th>Pclass</th>
                  <th>Name</th>
                  <th>Sex</th>
                  <th>Age</th>
                  <th>SibSp</th>
                  <th>Parch</th>
                  <th>Ticket</th>
                  <th>Fare</th>
                  <th>Cabin</th>
                  <th>Embarked</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>892</td>
                  <td>3</td>
                  <td>Kelly, Mr. James</td>
                  <td class="male">male</td>
                  <td>34.5</td>
                  <td>0</td>
                  <td>0</td>
                  <td>330911</td>
                  <td>7.8292</td>
                  <td>NaN</td>
                  <td>Q</td>
                </tr>
                <tr>
                  <td>893</td>
                  <td>3</td>
                  <td>Wilkes, Mrs. James (Ellen Needs)</td>
                  <td class="female">female</td>
                  <td>47.0</td>
                  <td>1</td>
                  <td>0</td>
                  <td>363272</td>
                  <td>7.0000</td>
                  <td>NaN</td>
                  <td>S</td>
                </tr>
                <tr>
                  <td>894</td>
                  <td>2</td>
                  <td>Myles, Mr. Thomas Francis</td>
                  <td class="male">male</td>
                  <td>62.0</td>
                  <td>0</td>
                  <td>0</td>
                  <td>240276</td>
                  <td>9.6875</td>
                  <td>NaN</td>
                  <td>Q</td>
                </tr>
                <tr>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                  <td>...</td>
                </tr>

                <tr>
                  <td>1307</td>
                  <td>3</td>
                  <td>Saether, Mr. Simon Sivertsen</td>
                  <td class="male">male</td>
                  <td>38.5</td>
                  <td>0</td>
                  <td>0</td>
                  <td>SOTON/O.Q. 3101262</td>
                  <td>7.2500</td>
                  <td>NaN</td>
                  <td>S</td>
                </tr>
                <tr>
                  <td>1308</td>
                  <td>3</td>
                  <td>Ware, Mr. Frederick</td>
                  <td class="male">male</td>
                  <td>NaN</td>
                  <td>0</td>
                  <td>0</td>
                  <td>359309</td>
                  <td>8.0500</td>
                  <td>NaN</td>
                  <td>S</td>
                </tr>
                <tr>
                  <td>1309</td>
                  <td>3</td>
                  <td>Peter, Master. Michael J</td>
                  <td class="male">male</td>
                  <td>NaN</td>
                  <td>1</td>
                  <td>1</td>
                  <td>2668</td>
                  <td>22.3583</td>
                  <td>NaN</td>
                  <td>C</td>
                </tr>
              </tbody>
            </table>

            </p>
          </div>
        </div>

      </g>

    </div>

    <div id="codeDiv">
      <p>
        Before diving into data analysis, it's crucial to first ensure the quality of our data. Higher-quality data
        leads to more reliable and insightful conclusions.
        Our dataset contains some missing data points, leaving the values for those entries unknown.
        This could be attributed to either the information being lost or not adequately collected. <br></br>
        First, let's import all the libraries we'll be using in this demonstration:
      </p>
      <pre>
        <code class = 'language-python'>
import pandas as pd #For Data Manipulation
import numpy as np #For Numerical Operations 
from sklearn.model_selection import train_test_split #To Split our dataset for training and validation purposes
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error #To evaluate our model
from catboost import CatBoostRegressor #This is to create our Machine Learning model</code>
      </pre>

      <p><br>
        Now, let's check which values are missing in our dataset by using pandas with the following python code:
      </p>
      <pre>
        <code class = 'language-python'>
#Reading CSV file
df = pd.read_csv('train.csv')

print(df.isnull().sum())</code>
      </pre>
      <p>
        <br>
        Which results on the following outcome:
      </p>

      <pre class="cmdFont">

        PassengerId      0 
        Survived         0
        Pclass           0
        Name             0
        Sex              0
        Age            177
        SibSp            0
        Parch            0
        Ticket           0
        Fare             0
        Cabin          687
        Embarked         2
        dtype: int64
      </pre>
      <p>
        <br>
        We can see that the Cabin, Age, and Embarked sections contain missing data. Of the 891 data points in our
        dataset,
        687 entries in the Cabin column are missing. Since this column doesn't really contribute much valuable
        information,
        we can go ahead and drop it. These missing values don’t offer any useful patterns for the model to learn from.


      <pre>
        <code class = 'language-python'>
#Dropping cabin column // # Setting inplace=True applies the change directly to the existing DataFrame
df.drop(columns=['Cabin'], inplace=True)</code>
      </pre>
      </p>
      <p>
        <br>
        For the Embarked section, we'll fill the two missing entries with the mode, since it's just a couple of values,
        using the most frequent category should work just fine.
        <br>
      <pre>
        <code class = 'language-python'>
#Calculating mode for Embarked Column and replacing missing values

print(df['Embarked'].value_counts()) #This shows us the value 'S' is the most repeated one
df['Embarked'] = df['Embarked'].fillna('S')</code>
      </pre>
      </p>
      <p>
        <br>
        Now, let’s take a look at how our dataset is shaping up in terms of missing values.
      <pre class='cmdFont'>
        <code >
        PassengerId      0
        Survived         0
        Pclass           0
        Name             0
        Sex              0
        Age            177
        SibSp            0
        Parch            0
        Ticket           0
        Fare             0
        Embarked         0
        dtype: int64</code>
      </pre>
      </p>
      <p>
        The Age column contains 177 missing values, to address this, we'll create a predictive model to estimate the
        missing ages.
        Why are we doing this?: The Age data could indicate underlying patterns worth investigating.
        However, before modeling, it's important to carry out feature selection to determine which variables are most
        relevant.
        <br></br>
        Let’s review the dataset's columns:<br>
        - PassengerId: This serves merely as an index and isn't necessary for our analysis at this stage. <br>
        - Survived: Our target variable for classification. Fortunately, it’s already well-formatted thanks to Kaggle’s
        preprocessing. <br>
        - Pclass: Represents ticket class, and it’s properly structured and ready for use. <br>
        - Name: While this field may not seem useful initially, it includes each passenger's title (e.g., Mr., Mrs.,
        Miss).
        We can extract these titles into a new feature column called Title, which may offer valuable insights. Let's see
        how to extract this information: <br>

      <pre>
  <code class="language-python">
#Adding new column 'Title'

pd.set_option('display.max_rows', None) #Used to display all the rows in our dataframe, this way we can explore it better

df['Title'] = None #Setting this column to none will help us filter the data by doing the following for each title we find:

df['Title'] = df['Name'].str.extract('(Mr\.)')
print(df['Title'].value_counts()) #Let's see how many values we were able to filter so far
print(df['Title'].isnull().value_counts()) #Let's see how many values on our new title column are empty

#This process was repeteated multiple times until we got the following filter: 
df['Title'] = df['Name'].str.extract(
'(Mr\.|Mrs\.|Miss|Dr\.|Master\.|Rev\.|Col\.|Major\.|Mlle\.|Jonkheer\.|Countess\. of|Mme\.|Don\.|Mme\.|Ms\.|Lady\.|Sir\.|Capt\.)'
)
print(df['Title'].value_counts()) 
print(df['Title'].isnull().value_counts()) #We should not have any null values left

df['Title'] = df['Title'].str.replace('.','') #Just taking out the '.' to make the column look better
</code>
</pre>
      </p>
      <p>
        - Sex: This feature is already properly formatted and ready for use.<br>
        - Age: This will serve as the target variable for our first predictive model.<br>
        - SibSp: Already clean and formatted correctly.<br>
        - Parch: No formatting issues, this column is good to go.<br>
        - Ticket: This column poses some challenges. Many of the entries appear inconsistent or unstructured,
        making it difficult to extract meaningful patterns. We'll attempt to clean and standardize this data by applying
        the same filtering techniques used earlier(It would have been easier to create a function to filter the data in
        stages, but I realized that halfway through writing the code. Lesson learned):
      </p>

      <pre>
<code class="language-python">

#Let's see if the data can be grouped and how is grouped
print('Initial Ticket Groups: \n',df['Ticket'].value_counts())


# Some entries contain purely numeric values, while others mix letters and numbers.
# Let's create a filter to isolate the entries with numeric-only values.
booleanMaskForNumbers = pd.to_numeric(df['Ticket'],errors='coerce').notna()

#This will show us the tickets that are only numbers
print('Numeric Tickets: \n', df.loc[booleanMaskForNumbers,['Ticket']].count())


#Let's begin filtering the data by creating a new column called 'NewTicket' with the information for the numeric tickets we just found

df['NewTicket'] = None
df.loc[booleanMaskForNumbers,['NewTicket']] = 'NUMERIC-TICKETS'

print('NewTicket Value counts: \n',df['NewTicket'].count()) #Let's see how many of the values on our new column are not empty


# Now, we will create a new filter for null values (values that have not been filtered yet), to avoid redefining the variable
# each time the dataframe changes, we will create a function that will create a boolean mask each time is called. 
# The function will have a reverse argument which will do the opposite

def get_unfiltered_values (reverse=False):
    if reverse == False:
        booleanMaskForNullValues = df['NewTicket'].isnull()
    else:
        booleanMaskForNullValues = ~df['NewTicket'].isnull()
    return booleanMaskForNullValues


# Now we can begin to filter the rest of the data in our ticket column, let's create another function that will print the
# remaining values that need to be filtered:
# The function will have a reverse argument which will do the opposite

def show_unfiltered_values(reverse=False):
    if reverse == False:
        print('Unfiltered values: \n',df.loc[get_unfiltered_values(),['Ticket','NewTicket']]) 
        #We are printing 'NewTicket' just to verify values are nulll
    else:
        print('Filtered values: \n', df.loc[get_unfiltered_values(reverse=True),['Ticket','NewTicket']])
    
show_unfiltered_values()

#tempBooleanMask will serve as a temporary mask for the letters and sequence of letters that need to be filtered

# 'PC' Categorical Value:

tempBooleanMask = df['Ticket'].str.contains('PC',case=False)

df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'PC'

show_unfiltered_values(reverse=False)


# 'SC/PARIS' Categorical Value: 

tempBooleanMask = df['Ticket'].str.contains('PARIS', case=False )
df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'SC/PARIS'


# 'CA' Categorical Value:

tempBooleanMask = df['Ticket'].str.contains('C', case=False ) & (
    df['Ticket'].str.contains('C',case=False)
) & (
    df['Ticket'].str.contains('A',case=False)
) & (
    ~(df['Ticket'].str.contains('S',case=False))
)

df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'CA'


# 'STON/02' Categorical Value:

tempBooleanMask = df['Ticket'].str.contains('SOTON', case=False )& (
    ~df['Ticket'].str.contains('C',case=False)
    ) | (
        df['Ticket'].str.contains('STON', case= False)
        )


df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'STON/02'



# 'SOC' Categorical Value:

tempBooleanMask = df['Ticket'].str.contains('S', case= False) & (
    df['Ticket'].str.contains('O',case=False)) & (
        df['Ticket'].str.contains('C',case=False)) & (
            ~df['Ticket'].str.contains('A|W',case=False)
        )
 
df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'SOC'



# 'SOPP' Categorical Value:


tempBooleanMask = df['Ticket'].str.contains('S',case= False) & (
    df['Ticket'].str.contains('O',case= False)
    ) & (
        df['Ticket'].str.contains('P',case= False)
        )


df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'SOPP'



# 'A5/A4' Categorical Value:

tempBooleanMask = df['Ticket'].str.contains('A') & df['Ticket'].str.contains('5') 

df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'A5/A4'


# 'FCC' Categorical Value: 

tempBooleanMask = df['Ticket'].str.contains('F',case=False) & ~df['Ticket'].str.contains('A',case=False)

df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'FCC'


# 'WC' Categorical Value:

tempBooleanMask = ( df['Ticket'].str.contains('W', case=False)) & (
    df['Ticket'].str.contains('C', case=False)
    ) & (
        ~df['Ticket'].str.contains('SCO',case=False)
        )

df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'WC'


# 'PP' Categorical Value: 

tempBooleanMask = df['Ticket'].str.contains('P',case=False) & (
~df['Ticket'].str.contains('S', case=False)
) & (
    ~df['Ticket'].str.contains('W', case=False)
    )


df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'PP'


# 'A5/A4' Categorical Value:

tempBooleanMask =  df['Ticket'].str.contains('A', case=False) & (
~df['Ticket'].str.contains('F',case=False)
) & (
    ~df['Ticket'].str.contains('SOTON') & ~df['Ticket'].str.contains('C')
    )

df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'A5/A4'


# 'LINE' Categorical Value:

tempBooleanMask = df['Ticket'].str.contains('LINE')

df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'LINE'




# 'C' Categorical Value:


tempBooleanMask = (
    df['Ticket'].str.contains('C', case=False) & ~df['Ticket'].str.contains('S', case=False)
)


df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'C'



# 'WEP' Categorical Value:


tempBooleanMask =  (
df['Ticket'].str.contains('W', case=False) & df['Ticket'].str.contains('E', case=False) & df['Ticket'].str.contains('P', case=False)
)

df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'WEP'



# 'SW/PP' Categorical Value:

tempBooleanMask =  ( df['Ticket'].str.contains('S', case=False) ) & (
    df['Ticket'].str.contains('W', case=False) 
    ) & (
        df['Ticket'].str.contains('P', case=False)
        )


df.loc[get_unfiltered_values() & tempBooleanMask, 'NewTicket'] = 'SW/PP'



# 'OTHER/STRINGS' Categorical Value: 

df.loc[get_unfiltered_values(),'NewTicket'] = 'OTHER/STRINGS'


show_unfiltered_values()</code>
</pre>
      <p><br>
        Now that we've cleaned our data, it's time to build a machine learning model to estimate the missing ages: <br>
      </p>
      <pre>
<code class="language-python">
#Let's save our original Data Frame for later
originalDF = df


#Let's select all of the relevant data for our model: 

print(df)

df = df[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Title','NewTicket']]


#Let's drop the missing age values
booleanMask = df['Age'].notnull()

df = df[booleanMask]


#Let's assign our target variable and our independent variables


x = df[['Survived','Pclass','Sex','SibSp','Parch','Fare','Embarked','Title','NewTicket']]
y = df['Age']


# We'll use the CatBoost Regressor, which excels at handling 
# categorical features like the ones below:

catColumns = ['Survived','Pclass','Sex','SibSp','Parch','Embarked','Title','NewTicket']


#Let's split our data to train and then test it: 

xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=42)




#Creating the model: 

model = CatBoostRegressor(

    iterations=500,
    learning_rate=0.03,
    depth=10,
    random_state=42,
    verbose=0,
 
)

model.fit(xTrain,yTrain,cat_features=catColumns)


yPred = model.predict(xTest)


# Let's calculate the evaluation metrics
mae = mean_absolute_error(yTest, yPred)
rmse = np.sqrt(mean_squared_error(yTest, yPred)) # RMSE is the sqrt of MSE
r2 = r2_score(yTest, yPred)

print("\nRegression Model Evaluation\n")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"On average, our age prediction is off by {mae:.2f} years\n")

print(f"Root Mean Squared Error (RMSE): {rmse:.2f}\n")

print(f"R-squared (R²): {r2:.2f}")
print(f"Our model explains {r2:.2%} of the variance in the age data\n")

# Let's look at the predictions values vs actual values uisng Tableau: 

results = pd.DataFrame({'Actual Age': yTest, 'Predicted Age': yPred})




# Our Model is good but it can be better, let's select only the best columns for our model 

print(model.get_feature_importance(prettified=True))


#Let's select all of the relevant data for our model: 


newDF = originalDF[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Title','NewTicket']]


#Let's drop the missing age values
booleanMask = newDF['Age'].notnull()

newDF = newDF[booleanMask]


#Let's assign our target variable and our independent variables


x = newDF[['Title','Pclass','Parch','Embarked','SibSp','Fare','NewTicket']]
y = newDF['Age']


# Let's indicate which are categorical values: 

catColumns = ['Title','Pclass','Parch','Embarked','SibSp','NewTicket']

#Let's split our data again to train and then test it: 

xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=42)


#Creating the model: 

model = CatBoostRegressor(

    iterations=500,
    learning_rate=0.03,
    depth=10,
    random_state=42,
    verbose=0,
 
)

model.fit(xTrain,yTrain,cat_features=catColumns)


yPred = model.predict(xTest)


# Let's calculate the evaluation metrics
mae = mean_absolute_error(yTest, yPred)
rmse = np.sqrt(mean_squared_error(yTest, yPred)) # RMSE is the sqrt of MSE
r2 = r2_score(yTest, yPred)

print("\nRegression Model Evaluation\n")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"On average, our age prediction is off by {mae:.2f} years\n")

print(f"Root Mean Squared Error (RMSE): {rmse:.2f}\n")

print(f"R-squared (R²): {r2:.2f}")
print(f"Our model explains {r2:.2%} of the variance in the age data\n")
</code>
</pre>

      <p><br>This is what we got:</p>

      <pre class="cmdFont">
  <code >
  
        Regression Model Evaluation

        Mean Absolute Error (MAE): 7.72
        On average, our age prediction is off by 7.72 years

        Root Mean Squared Error (RMSE): 9.85

        R-squared (R²): 0.48
        Our model explains 47.69% of the variance in the age data
  
  </code>
</pre>

      <p><br>
        While there's room to improve model accuracy, this configuration should be fine for our current objectives.
        Let's retrain the model using the complete dataset and save it:


      </p>

      <pre class="language-python">
  <code>
#Let's retrain our model with the full data set: 

model.fit(x,y,cat_features=catColumns)
print('Final Model has ben trained')


#Let's isolate the null values that we will be predicting: 

print(originalDF.isnull().sum())

nullAges = originalDF.loc[originalDF['Age'].isnull(),:]

print(nullAges)

x = nullAges[['Title','Pclass','Parch','Embarked','SibSp','Fare','NewTicket']]
y = nullAges['Age']

yPred = model.predict(x)


#On the original DF, let's assign the null values to the ones we just predicted

originalDF.loc[x.index,'Age'] = yPred

print(originalDF)


#Let's save our model to use it on the test.csv file
model.save_model('AgeRegressor.cbm')


#Let's save our results to use them to train our final model
originalDF.to_csv('Data Frame Cleaned.csv')
  </pre>
      </code>


      <p>
        The dataframe has been cleaned and we're ready to train our final model to predict survival outcomes.
        To keep this notebook concise, the remaining code is available on our <a href="../pages/pythonPage.html"
          style="text-decoration: none;color: #4A90E2; font-weight: 400;">Python Page</a>.

        And now that our data is prepared, let's visualize it using Tableau:

      </p>
      <div class='tableauPlaceholder' id='viz1752649348787' style='position: relative'><noscript><a href='#'><img
              alt='Titanic Data Visualization '
              src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ti&#47;TitanicDataVisualization_17512853832550&#47;TitanicDataVisualization&#47;1_rss.png'
              style='border: none' /></a></noscript><object class='tableauViz' style='display:none;'>
          <param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' />
          <param name='embed_code_version' value='3' />
          <param name='site_root' value='' />
          <param name='name' value='TitanicDataVisualization_17512853832550&#47;TitanicDataVisualization' />
          <param name='tabs' value='no' />
          <param name='toolbar' value='yes' />
          <param name='static_image'
            value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ti&#47;TitanicDataVisualization_17512853832550&#47;TitanicDataVisualization&#47;1.png' />
          <param name='animate_transition' value='yes' />
          <param name='display_static_image' value='yes' />
          <param name='display_spinner' value='yes' />
          <param name='display_overlay' value='yes' />
          <param name='display_count' value='yes' />
          <param name='language' value='en-US' />
          <param name='filter' value='publish=yes' />
        </object></div>
      <script
        type='text/javascript'>                    var divElement = document.getElementById('viz1752649348787'); var vizElement = divElement.getElementsByTagName('object')[0]; vizElement.style.width = '100%'; vizElement.style.height = (divElement.offsetWidth * 0.75) + 'px'; var scriptElement = document.createElement('script'); scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js'; vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>
      <script src="../js/shipPage.js"></script>
      <script src="../js/prism.js"></script>
</body>

</html>